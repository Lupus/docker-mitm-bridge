# Default values for kyverno-intercept chart

# Namespace configuration
namespace: kyverno-intercept

# Internal CA configuration
ca:
  # Generate CA on installation
  generate: true
  # CA validity in days
  validity: 3650
  subject:
    country: US
    state: CA
    organization: Internal-CA
    commonName: Kyverno-Intercept-CA

# Domains to intercept - these will have certificates pre-generated
interceptDomains:
  github:
    enabled: true
    domains:
      - "github.com"
      - "api.github.com"
      - "raw.githubusercontent.com"

  aws:
    enabled: true
    domains:
      - "s3.amazonaws.com"
      - "ec2.amazonaws.com"
      - "sts.amazonaws.com"

  google:
    enabled: false
    domains:
      - "googleapis.com"
      - "storage.googleapis.com"

# Certificate configuration
certificates:
  duration: 8760h  # 1 year
  renewBefore: 720h  # 30 days before expiry

# Envoy proxy configuration
envoy:
  image: envoyproxy/envoy:v1.33-latest
  resources:
    limits:
      memory: "256Mi"
      cpu: "200m"
    requests:
      memory: "128Mi"
      cpu: "100m"
  port: 15001      # HTTP proxy port (sidecar infrastructure range)
  httpsPort: 15002 # HTTPS proxy port (sidecar infrastructure range)
  adminPort: 15000 # Admin interface
  uid: 101         # Run as non-root user
  gid: 101
  logLevel: info

# xDS (Control Plane) configuration
xds:
  enabled: true
  image:
    repository: ghcr.io/lupus/docker-mitm-bridge/xds-service
    tag: latest
    pullPolicy: Always
  grpcPort: 15080   # gRPC port for xDS (sidecar infrastructure range)
  httpPort: 15081   # HTTP port for CA distribution
  uid: 103          # Run as non-root user
  gid: 103
  resources:
    limits:
      memory: "128Mi"
      cpu: "200m"
    requests:
      memory: "64Mi"
      cpu: "100m"

# OPA sidecar configuration
opa:
  enabled: true
  image: openpolicyagent/opa:latest-envoy
  resources:
    limits:
      memory: "128Mi"
      cpu: "100m"
    requests:
      memory: "64Mi"
      cpu: "50m"
  port: 15020      # HTTP API (sidecar infrastructure range)
  grpcPort: 15021  # gRPC ext_authz port
  uid: 102         # Run as non-root user
  gid: 102

  # OPA policy configuration (imported from docker-mitm-bridge)
  policy:
    # Domains with restricted access (only GET/HEAD allowed)
    allowedDomains:
      - github.com
      - api.github.com
      - raw.githubusercontent.com
      - pypi.org
      - files.pythonhosted.org
      - registry.npmjs.org
      - crates.io
      - archive.ubuntu.com
      - deb.debian.org

    # Domains with unrestricted access (all HTTP methods)
    unrestrictedDomains:
      - api.anthropic.com
      - console.anthropic.com
      - api.openai.com
      - http-server  # Test HTTP server for cluster separation tests
      - http-server.kyverno-intercept.svc.cluster.local

    # GitHub-specific configuration
    githubReadAccessEnabled: true
    githubAllowedUsers: []
    githubAllowedRepos:
      - "Lupus/circuitry-cad"

    # AWS-specific configuration
    awsAccessEnabled: false
    awsAllowedServices: []
      # Example: ["s3", "ec2", "sts"]

# Init container configuration
initContainer:
  image: nicolaka/netshoot:latest
  # iptables rules configuration
  redirectPorts:
    - 80
    - 443
  # Port isolation config
  sidecarPortRangeStart: 15000  # Start of sidecar infrastructure range
  sidecarPortRangeEnd: 15099    # End of sidecar infrastructure range
  privilegedPortEnd: 1023       # Privileged ports to block (0-1023)

# Kyverno policy configuration
kyverno:
  # Annotation to trigger sidecar injection
  annotationKey: "intercept-proxy/enabled"
  annotationValue: "true"

  # Whether to inject environment variables
  injectEnvVars: false
  envVars:
    HTTP_PROXY: "http://localhost:15001"
    HTTPS_PROXY: "http://localhost:15001"
    NO_PROXY: "localhost,127.0.0.1,10.0.0.0/8,.cluster.local"

# Test workload configuration
testWorkload:
  enabled: true
  name: intercept-test
  image: curlimages/curl:latest
  replicas: 1

# Monitoring and observability
monitoring:
  enabled: false
  prometheus:
    enabled: false
    port: 9090

# Cleanup hook configuration
cleanup:
  enabled: true

# NetworkPolicy configuration - blocks cloud metadata service access
# Mitigates SECURITY_ASSESSMENT.md vulnerability #3: OPA Policy Injection via K8s API
#
# Security Model:
# - PRIMARY PROTECTION: automountServiceAccountToken: false (set via Kyverno mutation)
#   prevents K8s API access by removing credentials from the pod
# - SECONDARY PROTECTION: NetworkPolicy blocks cloud metadata service (169.254.169.254)
#   which could leak credentials in cloud environments
#
# Note: We intentionally do NOT block the K8s service CIDR (10.96.0.0/12) because:
# 1. automountServiceAccountToken: false already prevents authenticated K8s API access
# 2. Blocking the service CIDR would break access to legitimate in-cluster services
# 3. Anonymous K8s API access is typically disabled in production clusters
networkPolicy:
  # Disabled by default - requires CNI with NetworkPolicy support (Calico, Cilium, etc.)
  # Enable if your cluster supports NetworkPolicy and you want to block cloud metadata service
  enabled: false

  # CIDRs to block from intercepted pods
  blockedCIDRs:
    # Cloud metadata services (AWS, GCP, Azure all use this IP)
    # This prevents credential theft via IMDS in cloud environments
    - "169.254.169.254/32"

    # AWS IMDSv2 IPv6 (uncomment if using IPv6 in AWS)
    # - "fd00:ec2::254/128"

    # Optional: Block K8s API server IP directly if known
    # Note: Only enable this if you know your cluster's API server IP
    # and don't need any in-cluster service access
    # - "10.96.0.1/32"  # Typical K8s API server IP (first IP in service CIDR)

  # Allow communication between pods in the same namespace
  # Enable this if intercepted pods need to communicate with other pods
  allowIntraNamespace: false

  # Additional egress rules (advanced configuration)
  # Example:
  # additionalAllowedEgress:
  #   - to:
  #       - ipBlock:
  #           cidr: 10.0.0.0/8
  #     ports:
  #       - protocol: TCP
  #         port: 6379
  additionalAllowedEgress: []